{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from skimage.color import lab2rgb, rgb2lab\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from cGAN_CL.compute_metrics import compute_metrics\n",
    "from cGAN.models import MainModel, build_res_unet \n",
    "from COLORIZATION.colorizers import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fa2864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2_outputs(data_path, model, device): \n",
    "    #Image transformation\n",
    "    SIZE = 256\n",
    "    class ColorizationDataset(Dataset):\n",
    "        def __init__(self, paths):\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE), Image.BICUBIC),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            self.paths = paths\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            try:\n",
    "                img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "                img = self.transforms(img)\n",
    "                img_np = np.array(img.permute(1, 2, 0))  # Convert to HWC format for rgb2lab\n",
    "                img_lab = rgb2lab(img_np).astype(\"float32\")\n",
    "                img_lab = torch.tensor(img_lab).permute(2, 0, 1)  # Convert to CHW format\n",
    "                L = img_lab[[0], ...] / 50. - 1.  # Normalize L\n",
    "                ab = img_lab[[1, 2], ...] / 110.  # Normalize ab\n",
    "                return {'L': L, 'ab': ab, 'path': self.paths[idx]}\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {self.paths[idx]}: {e}\")\n",
    "                return None  # Skip the image\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.paths)\n",
    "\n",
    "    def make_dataloader(data_path, batch_size=16, num_workers=2, pin_memory=True):\n",
    "        dataset = ColorizationDataset(data_path)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle = False, pin_memory=pin_memory)\n",
    "        return dataloader\n",
    "\n",
    "    def colorize_model2(data, model, device):\n",
    "        colorized_results = []\n",
    "        for batch in tqdm(data, desc=\"Model: Colorizing images\"):\n",
    "            if batch is None:\n",
    "                continue  # Skip corrupted images\n",
    "            \n",
    "            L, ab, paths = batch['L'].to(device), batch['ab'].to(device), batch['path']\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_ab = model.net_G(L)  # Output should be ab channels\n",
    "            \n",
    "            for i in range(len(paths)):\n",
    "                L_img = (L[i].cpu().numpy() + 1.) * 50.  # De-normalize L\n",
    "                pred_ab_img = pred_ab[i].cpu().numpy() * 110.  # De-normalize ab\n",
    "                lab_img = np.concatenate((L_img, pred_ab_img), axis=0).transpose(1, 2, 0)\n",
    "                colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
    "                colorized_rgb = torch.from_numpy(colorized_rgb).permute(2, 0, 1)  # Convert to CHW format\n",
    "                colorized_results.append(colorized_rgb)\n",
    "        return colorized_results\n",
    "\n",
    "    data = make_dataloader(data_path)\n",
    "    return colorize_model2(data, model, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e90e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1_outputs(data_path, colorizer, device):\n",
    "    colorised_results = []\n",
    "    for img_path in tqdm(data_path):\n",
    "        try:\n",
    "            img = load_img(img_path)\n",
    "            (tens_l_orig, tens_l_rs) = preprocess_img(img, HW=(256, 256))\n",
    "\n",
    "            tens_l_rs = tens_l_rs.cuda()\n",
    "            out_img_siggraph17 = postprocess_tens(tens_l_orig, colorizer(tens_l_rs).cpu())\n",
    "            result = (np.clip(out_img_siggraph17, 0, 1) * 255).astype(np.uint8)\n",
    "            result = torch.from_numpy(result)  # Convert NumPy array to PyTorch tensor\n",
    "            result = result.permute(2, 0, 1)  # Example: for changing HWC → CHW\n",
    "            colorised_results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    return colorised_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ff6d8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/student/2021/cs21btech11002/miniconda3/envs/cGAN/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/u/student/2021/cs21btech11002/miniconda3/envs/cGAN/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized with norm initialization\n",
      "Model 1 and Model 2 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model1 = siggraph17(pretrained=True).eval()\n",
    "model1.cuda()\n",
    "\n",
    "\n",
    "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
    "model2 = MainModel(net_G=net_G)\n",
    "model2.load_state_dict(torch.load(\"/u/student/2021/cs21btech11002/CV_Project/cGAN/cGAN-unet.pt\", map_location=device))  # Load trained MainModel\n",
    "model2.to(device)\n",
    "model2.eval()\n",
    "print(\"Model 1 and Model 2 loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a638af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_weighted_mse_loss(model1_output, model2_output, selector_probs, target):\n",
    "    mse1 = ((model1_output.float() - target.float()) ** 2).mean(dim=[1,2,3])  # [B]\n",
    "    mse2 = ((model2_output.float() - target.float()) ** 2).mean(dim=[1,2,3])  # [B]\n",
    "    weighted_loss = selector_probs[:, 0] * mse1 + selector_probs[:, 1] * mse2  # [B]\n",
    "    return weighted_loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e57796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train paths: 1600, Test paths: 19959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1600 [00:03<06:50,  3.87it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 2 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  2%|▏         | 24/1600 [00:06<06:16,  4.18it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 13 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  2%|▏         | 26/1600 [00:06<07:22,  3.55it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 3 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  2%|▏         | 38/1600 [00:09<06:17,  4.14it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 7 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  3%|▎         | 41/1600 [00:10<06:46,  3.84it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 33 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  3%|▎         | 42/1600 [00:10<07:04,  3.67it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 9 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  3%|▎         | 55/1600 [00:14<06:31,  3.95it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 1 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  5%|▌         | 85/1600 [00:22<06:48,  3.71it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 32 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  6%|▋         | 103/1600 [00:27<06:24,  3.89it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 39 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  7%|▋         | 112/1600 [00:29<07:13,  3.44it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 18 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  8%|▊         | 123/1600 [00:33<12:18,  2.00it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 4 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  9%|▉         | 144/1600 [00:40<05:19,  4.56it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 17 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  9%|▉         | 147/1600 [00:41<05:05,  4.75it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 26 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 13%|█▎        | 210/1600 [00:57<05:03,  4.58it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 22 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 14%|█▍        | 223/1600 [01:00<04:59,  4.60it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 19 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 15%|█▍        | 237/1600 [01:03<04:58,  4.56it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 12 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 16%|█▌        | 257/1600 [01:08<06:08,  3.64it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 197 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 17%|█▋        | 275/1600 [01:12<04:58,  4.44it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 86 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 20%|██        | 320/1600 [01:23<05:28,  3.90it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 11 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 20%|██        | 322/1600 [01:24<05:56,  3.59it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 60 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 21%|██▏       | 343/1600 [01:29<05:37,  3.73it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 284 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 22%|██▏       | 352/1600 [01:31<04:38,  4.48it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 6 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 23%|██▎       | 362/1600 [01:33<04:58,  4.15it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 1154 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 23%|██▎       | 372/1600 [01:36<05:05,  4.02it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 8 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 30%|██▉       | 479/1600 [02:01<04:43,  3.96it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 34 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 37%|███▋      | 589/1600 [02:26<03:39,  4.60it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 20 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 37%|███▋      | 594/1600 [02:27<03:16,  5.12it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 205 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 38%|███▊      | 616/1600 [02:32<03:50,  4.28it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 10 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 41%|████      | 649/1600 [02:41<03:44,  4.23it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 29 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 41%|████▏     | 662/1600 [02:44<03:45,  4.17it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 160 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 43%|████▎     | 682/1600 [02:48<03:38,  4.21it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 28 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 44%|████▍     | 703/1600 [02:53<03:28,  4.30it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 30 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 47%|████▋     | 754/1600 [03:04<03:06,  4.54it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 14 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 48%|████▊     | 768/1600 [03:07<03:15,  4.25it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 972 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 49%|████▉     | 786/1600 [03:12<03:09,  4.30it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 40 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 53%|█████▎    | 855/1600 [03:27<02:37,  4.73it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 75 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 64%|██████▎   | 1016/1600 [03:59<01:47,  5.43it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 50 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 65%|██████▌   | 1045/1600 [04:05<01:53,  4.89it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 66 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 68%|██████▊   | 1085/1600 [04:12<01:26,  5.94it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 36 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 70%|███████   | 1127/1600 [04:20<01:37,  4.86it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 15 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 80%|███████▉  | 1275/1600 [04:50<00:48,  6.69it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 35 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 91%|█████████▏| 1460/1600 [05:31<00:27,  5.12it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 5 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 97%|█████████▋| 1558/1600 [05:49<00:09,  4.64it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 27 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "100%|██████████| 1600/1600 [05:57<00:00,  4.47it/s]\n",
      "Model: Colorizing images:   3%|▎         | 3/100 [00:01<00:42,  2.30it/s]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 1 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images:  17%|█▋        | 17/100 [00:04<00:18,  4.51it/s]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 6 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images:  37%|███▋      | 37/100 [00:09<00:13,  4.54it/s]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 2 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images: 100%|██████████| 100/100 [00:23<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# === Configuration ===\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "DATA_DIR = \"../unlabeled2017\" # folder containing 'train' and 'val' subfolders\n",
    "\n",
    "paths_coco = glob(os.path.join(DATA_DIR, '../unlabeled2017', '*'))\n",
    "paths_image_net = glob(os.path.join(DATA_DIR, '../ImageNet', '**', '*.JPEG'), recursive=True)\n",
    "train_paths = paths_coco[:800] + paths_image_net[:800]\n",
    "\n",
    "model1_train_outputs = model1_outputs(train_paths, model1, device)\n",
    "model2_train_outputs = model2_outputs(train_paths, model2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "381264ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Transforms for Grayscale + Inception ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), Image.BICUBIC)\n",
    "])\n",
    "transform_input = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224), Image.BICUBIC),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "class EnsembleTrainingDataset(Dataset):\n",
    "    def __init__(self, image_paths, m1_outputs, m2_outputs, transform=None, transform_input=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.m1_outputs = m1_outputs\n",
    "        self.m2_outputs = m2_outputs\n",
    "        self.transform = transform\n",
    "        self.transform_input = transform_input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        image_rgb = Image.open(path).convert(\"RGB\")\n",
    "        input = self.transform_input(image_rgb) if self.transform_input else image_rgb\n",
    "        image_rgb = torch.tensor(np.array(image_rgb)).permute(2, 0, 1)\n",
    "        target = self.transform(image_rgb) if self.transform else image_rgb\n",
    "        out1 = self.m1_outputs[idx]\n",
    "        out2 = self.m2_outputs[idx]\n",
    "        out1 = self.transform(out1) if self.transform else out1\n",
    "        out2 = self.transform(out2) if self.transform else out2\n",
    "\n",
    "        return input, out1, out2, target\n",
    "\n",
    "train_dataset = EnsembleTrainingDataset(train_paths, model1_train_outputs, model2_train_outputs, transform=transform, transform_input=transform_input)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b616a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n",
      "  4%|▍         | 1/25 [00:22<08:57, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 269.6669006347656\n",
      "\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:15<00:00,  3.17it/s]\n",
      "  8%|▊         | 2/25 [00:38<07:05, 18.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 255.57003784179688\n",
      "\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n",
      " 12%|█▏        | 3/25 [00:54<06:27, 17.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 225.3173370361328\n",
      "\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.94it/s]\n",
      " 16%|█▌        | 4/25 [01:11<06:05, 17.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 218.83319091796875\n",
      "\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.06it/s]\n",
      " 20%|██        | 5/25 [01:28<05:40, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 213.67446899414062\n",
      "\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.97it/s]\n",
      " 24%|██▍       | 6/25 [01:45<05:22, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 212.14181518554688\n",
      "\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:28<00:00,  2.97s/it]\n",
      " 28%|██▊       | 7/25 [04:13<17:59, 59.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 211.1863250732422\n",
      "\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:35<00:00,  1.41it/s]\n",
      " 32%|███▏      | 8/25 [04:49<14:47, 52.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 210.49668884277344\n",
      "\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.96it/s]\n",
      " 36%|███▌      | 9/25 [05:05<10:58, 41.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 209.9573211669922\n",
      "\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.86it/s]\n",
      " 40%|████      | 10/25 [05:23<08:27, 33.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 209.5076446533203\n",
      "\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.88it/s]\n",
      " 44%|████▍     | 11/25 [05:40<06:43, 28.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 209.11358642578125\n",
      "\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n",
      " 48%|████▊     | 12/25 [05:57<05:26, 25.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 208.75965881347656\n",
      "\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.93it/s]\n",
      " 52%|█████▏    | 13/25 [06:14<04:32, 22.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 208.43527221679688\n",
      "\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.89it/s]\n",
      " 56%|█████▌    | 14/25 [06:31<03:51, 21.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 208.1365509033203\n",
      "\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      " 60%|██████    | 15/25 [06:48<03:17, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 207.8604278564453\n",
      "\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      " 64%|██████▍   | 16/25 [07:05<02:49, 18.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 207.6086883544922\n",
      "\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.06it/s]\n",
      " 68%|██████▊   | 17/25 [07:21<02:24, 18.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 207.368896484375\n",
      "\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.98it/s]\n",
      " 72%|███████▏  | 18/25 [07:38<02:03, 17.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 207.13534545898438\n",
      "\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      " 76%|███████▌  | 19/25 [07:55<01:44, 17.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 206.89697265625\n",
      "\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.92it/s]\n",
      " 80%|████████  | 20/25 [08:12<01:26, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 206.64016723632812\n",
      "\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.01it/s]\n",
      " 84%|████████▍ | 21/25 [08:28<01:08, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 206.36529541015625\n",
      "\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      " 88%|████████▊ | 22/25 [08:45<00:50, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 206.0771484375\n",
      "\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.96it/s]\n",
      " 92%|█████████▏| 23/25 [09:02<00:33, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 205.7972412109375\n",
      "\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.86it/s]\n",
      " 96%|█████████▌| 24/25 [09:20<00:17, 17.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 205.54884338378906\n",
      "\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.11it/s]\n",
      "100%|██████████| 25/25 [09:36<00:00, 23.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 205.3300323486328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# === Load CLIP ===\n",
    "clip_model, preprocess_clip = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.eval()\n",
    "\n",
    "# Freeze CLIP\n",
    "for param in clip_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace CLIP image encoder's projection with a custom selector head\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "selector_head = nn.Sequential(\n",
    "    nn.Linear(clip_model.visual.output_dim, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, NUM_CLASSES)\n",
    ").to(device)\n",
    "\n",
    "selector_head.apply(init_weights)\n",
    "\n",
    "# Optimizer for selector head\n",
    "optimizer = optim.Adam(selector_head.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# === Training Loop ===\n",
    "NUM_EPOCHS = 25\n",
    "losses = []\n",
    "updates = 0\n",
    "non_updates = 0\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\") \n",
    "    running_loss = 0.0\n",
    "    for input_img, out1, out2, target in tqdm(train_loader):\n",
    "        input_img = input_img.to(device)       # Grayscale: [B, 1, H, W]\n",
    "        out1 = out1.to(device)\n",
    "        out2 = out2.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Convert to 3 channels (RGB format for CLIP)\n",
    "        input_rgb = input_img.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Resize and normalize input for CLIP using preprocess (same as transforms for CLIP)\n",
    "        input_rgb = nn.functional.interpolate(input_rgb, size=224, mode='bicubic', align_corners=False)\n",
    "        input_rgb = input_rgb.clamp(0, 1)  # Ensure range is [0, 1]\n",
    "\n",
    "        # Normalize manually using CLIP mean/std\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "            std=[0.26862954, 0.26130258, 0.27577711]\n",
    "        )\n",
    "        input_rgb = normalize(input_rgb)\n",
    "\n",
    "        # Get CLIP visual embeddings\n",
    "        with torch.no_grad():\n",
    "            features = clip_model.encode_image(input_rgb)  # [B, D]\n",
    "            features = features.float()\n",
    "        \n",
    "        # Predict selector probabilities\n",
    "        selector_logits = selector_head(features)  # [B, NUM_CLASSES]\n",
    "        selector_probs = torch.softmax(selector_logits, dim=1)  # [B, NUM_CLASSES]\n",
    "\n",
    "        # Compute weighted MSE loss\n",
    "        loss = ensemble_weighted_mse_loss(out1, out2, selector_probs, target)\n",
    "        # Check if weights are updated\n",
    "        before_update = selector_head[2].weight.clone()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        after_update = selector_head[2].weight.clone()\n",
    "        if torch.equal(before_update, after_update):\n",
    "            non_updates += 1\n",
    "        else:\n",
    "            updates += 1\n",
    "        running_loss += loss\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Training Loss: {epoch_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7104fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(losses) + 1), [loss.item() for loss in losses], marker='o', label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70899d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_loader):\n",
    "    choices = []\n",
    "    best = []\n",
    "    for input_img, out1, out2, target in tqdm(test_loader):\n",
    "        input_img = input_img.to(device)\n",
    "        out1 = out1.to(device)\n",
    "        out2 = out2.to(device)\n",
    "        target = target.to(device)\n",
    "        # Convert to 3 channels (RGB format for CLIP)\n",
    "        input_rgb = input_img.repeat(1, 3, 1, 1)\n",
    "        # Resize and normalize input for CLIP using preprocess (same as transforms for CLIP)\n",
    "        input_rgb = nn.functional.interpolate(input_rgb, size=224, mode='bicubic', align_corners=False)\n",
    "        input_rgb = input_rgb.clamp(0, 1)  # Ensure range is [0, 1]\n",
    "        # Normalize manually using CLIP mean/std\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "            std=[0.26862954, 0.26130258, 0.27577711]\n",
    "        )\n",
    "        input_rgb = normalize(input_rgb)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = clip_model.encode_image(input_rgb)  # [B, D]\n",
    "            features = features.float()\n",
    "            # Predict selector probabilities\n",
    "            selector_logits = selector_head(features)  # [B, NUM_CLASSES]\n",
    "            selector_probs = torch.softmax(selector_logits, dim=1)  # [B, NUM_CLASSES]\n",
    "            mse1 = ((out1.float() - target.float()) ** 2).mean(dim=[1,2,3])  # [B]\n",
    "            mse2 = ((out2.float() - target.float()) ** 2).mean(dim=[1,2,3])  # [B]\n",
    "            best.extend((mse2<=mse1).int())\n",
    "            choices.extend(torch.argmax(selector_probs, dim=1))\n",
    "            \n",
    "    return choices, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d988478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_path):\n",
    "    model1_test_outputs = model1_outputs(test_path, model1, device)\n",
    "    model2_test_outputs = model2_outputs(test_path, model2, device)\n",
    "    test_dataset = EnsembleTrainingDataset(test_path, model1_test_outputs, model2_test_outputs, transform=transform, transform_input=transform_input)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE*4, shuffle=False, num_workers=2)\n",
    "    choices, best_choices = test_model(test_loader)\n",
    "    # Find overlap between best_choices and choices\n",
    "    index = [i for i, (best, choice) in enumerate(zip(best_choices, choices)) if best == choice]\n",
    "    overlap = sum(1 for best, choice in zip(best_choices, choices) if best == choice)\n",
    "    choices_tensor = torch.tensor(choices)\n",
    "    num_ones = (choices_tensor == 1).sum().item()\n",
    "    num_zeros = (choices_tensor == 0).sum().item()\n",
    "    print(f\"Number of 1's: {num_ones}\")\n",
    "    print(f\"Number of 0's: {num_zeros}\")\n",
    "    print(f\"Accuracy: {overlap/len(choices) * 100:.2f}%\")\n",
    "    return choices, model1_test_outputs, model2_test_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "828851cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths_coco_test = sorted(glob(os.path.join(DATA_DIR, '../test_COCO', '*')))[:2000]\n",
    "paths_image_net_test = sorted(glob(os.path.join(DATA_DIR, '../test_ImageNet', '*')))[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23c199e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [07:27<00:00,  4.47it/s]\n",
      "Model: Colorizing images:   1%|          | 1/125 [00:01<02:52,  1.39s/it]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 1 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images:   6%|▌         | 7/125 [00:02<00:36,  3.27it/s]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 5 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images:  26%|██▋       | 33/125 [00:09<00:21,  4.20it/s]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 7 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images:  46%|████▋     | 58/125 [00:15<00:15,  4.26it/s]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 39 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images:  53%|█████▎    | 66/125 [00:17<00:16,  3.60it/s]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 3 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images:  68%|██████▊   | 85/125 [00:24<00:11,  3.56it/s]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 2 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images: 100%|██████████| 125/125 [00:34<00:00,  3.57it/s]\n",
      "100%|██████████| 16/16 [00:26<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's: 1833\n",
      "Number of 0's: 167\n",
      "Accuracy: 71.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "choices_coco, m1_coco, m2_coco = inference(paths_coco_test)\n",
    "results_coco = [m1 if choice == 0 else m2 for choice, m1, m2 in zip(choices_coco, m1_coco, m2_coco)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f96bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31/2000 [00:06<06:07,  5.35it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 1 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  8%|▊         | 155/2000 [00:28<05:40,  5.42it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 21 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "  8%|▊         | 157/2000 [00:28<05:39,  5.44it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 2 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 12%|█▏        | 242/2000 [00:45<05:59,  4.89it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 11 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 12%|█▏        | 247/2000 [00:45<04:16,  6.83it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 4 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 13%|█▎        | 264/2000 [00:48<04:36,  6.28it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 14 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 13%|█▎        | 265/2000 [00:49<04:51,  5.95it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 33 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 14%|█▎        | 272/2000 [00:50<04:59,  5.77it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 8 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 16%|█▋        | 330/2000 [01:00<04:06,  6.79it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 12 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 17%|█▋        | 342/2000 [01:02<05:00,  5.52it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 3 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 17%|█▋        | 344/2000 [01:03<04:48,  5.74it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 6 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 17%|█▋        | 349/2000 [01:03<04:19,  6.37it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 29 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 18%|█▊        | 355/2000 [01:05<05:00,  5.47it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 77 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 18%|█▊        | 364/2000 [01:06<04:30,  6.05it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 10 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 18%|█▊        | 369/2000 [01:07<04:48,  5.65it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 9 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 20%|██        | 400/2000 [01:12<04:46,  5.58it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 31 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 20%|██        | 406/2000 [01:13<04:14,  6.25it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 46 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 20%|██        | 409/2000 [01:13<04:16,  6.20it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 1018 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 21%|██        | 412/2000 [01:14<04:44,  5.59it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 5 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 21%|██▏       | 425/2000 [01:16<04:08,  6.34it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 45 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 21%|██▏       | 428/2000 [01:17<04:30,  5.80it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 36 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 22%|██▏       | 443/2000 [01:19<04:25,  5.86it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 27 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 24%|██▍       | 481/2000 [01:25<03:31,  7.19it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 24 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 25%|██▍       | 491/2000 [01:27<03:55,  6.42it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 18 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 31%|███       | 620/2000 [01:46<03:44,  6.16it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 394 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 36%|███▌      | 719/2000 [02:04<03:29,  6.12it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 13 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 37%|███▋      | 732/2000 [02:06<02:48,  7.51it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 7 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 38%|███▊      | 750/2000 [02:09<03:33,  5.86it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 67 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 38%|███▊      | 751/2000 [02:09<03:32,  5.88it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 278 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 39%|███▉      | 777/2000 [02:14<03:30,  5.81it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 100 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 41%|████▏     | 827/2000 [02:23<03:13,  6.05it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 115 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 48%|████▊     | 956/2000 [02:45<02:22,  7.31it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 51 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 55%|█████▍    | 1099/2000 [03:11<02:26,  6.16it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 22 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 66%|██████▋   | 1328/2000 [03:49<01:52,  5.98it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 52 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 69%|██████▉   | 1384/2000 [03:59<01:39,  6.18it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 211 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 74%|███████▎  | 1473/2000 [04:13<01:36,  5.44it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 198 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 76%|███████▋  | 1526/2000 [04:21<01:03,  7.45it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 17 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 78%|███████▊  | 1550/2000 [04:25<01:05,  6.91it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 92 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 78%|███████▊  | 1555/2000 [04:25<01:17,  5.78it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 39 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 89%|████████▉ | 1782/2000 [05:04<00:38,  5.60it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 23 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      " 95%|█████████▍| 1891/2000 [05:24<00:21,  5.05it/s]/u/student/2021/cs21btech11002/CV_Project/COLORIZATION/colorizers/util.py:47: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 233 negative Z values that have been clipped to zero\n",
      "  return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))\n",
      "100%|██████████| 2000/2000 [05:44<00:00,  5.80it/s]\n",
      "Model: Colorizing images:   2%|▏         | 2/125 [00:01<01:30,  1.36it/s]/tmp/ipykernel_2183398/1344644219.py:49: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 1 negative Z values that have been clipped to zero\n",
      "  colorized_rgb = (lab2rgb(lab_img) * 255).astype(\"uint8\")\n",
      "Model: Colorizing images: 100%|██████████| 125/125 [00:29<00:00,  4.24it/s]\n",
      "100%|██████████| 16/16 [00:21<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's: 1989\n",
      "Number of 0's: 11\n",
      "Accuracy: 17.55%\n"
     ]
    }
   ],
   "source": [
    "choices_imagenet, m1_imagenet, m2_imagenet = inference(paths_image_net_test)\n",
    "results_imagenet = [m1 if choice == 0 else m2 for choice, m1, m2 in zip(choices_imagenet, m1_imagenet, m2_imagenet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "148015f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorized_results_coco = [(orig_img, result) for orig_img, result in zip(paths_coco_test, results_coco)]\n",
    "colorized_results_imagenet = [(orig_img, result) for orig_img, result in zip(paths_image_net_test, results_imagenet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f361ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def eval(test_path, colorized_results):    \n",
    "    # Compute metrics\n",
    "    ssim_scores = []\n",
    "    colorfulness_scores = []\n",
    "    color_harmony_scores = []\n",
    "    color_balance_scores = []\n",
    "    pcqi_scores = []\n",
    "    lpips_scores = []\n",
    "\n",
    "    for orig_img, colorized_rgb in tqdm(colorized_results):\n",
    "        orig_img = cv2.imread(orig_img)\n",
    "        orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "        #orig_img = np.array(orig_img).transpose(2, 0, 1)  # Convert to CHW format\n",
    "\n",
    "        colorized_rgb = np.array(colorized_rgb).transpose(1, 2, 0)  # Convert to HWC format\n",
    "        metrics = compute_metrics(orig_img, colorized_rgb)\n",
    "\n",
    "        ssim_scores.append(metrics['SSIM'])\n",
    "        colorfulness_scores.append(metrics['Colorfulness'])\n",
    "        color_harmony_scores.append(metrics['Color Harmony'])\n",
    "        color_balance_scores.append(metrics['Color Balance'])\n",
    "        pcqi_scores.append(metrics['PCQI'])\n",
    "        lpips_scores.append(metrics['LPIPS']) \n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_ssim = np.mean(ssim_scores)\n",
    "    avg_colorfulness = np.mean(colorfulness_scores)\n",
    "    avg_color_harmony = np.mean(color_harmony_scores)\n",
    "    avg_color_balance = np.mean(color_balance_scores)\n",
    "    avg_pcqi = np.mean(pcqi_scores)\n",
    "    avg_lpips = np.mean(lpips_scores)\n",
    "\n",
    "    # Calculate standard deviation scores\n",
    "    std_ssim = np.std(ssim_scores)\n",
    "    std_colorfulness = np.std(colorfulness_scores)\n",
    "    std_color_harmony = np.std(color_harmony_scores)\n",
    "    std_color_balance = np.std(color_balance_scores)\n",
    "    std_pcqi = np.std(pcqi_scores)\n",
    "    std_lpips = np.std(lpips_scores)\n",
    "\n",
    "    if test_path == paths_coco_test:\n",
    "        print(\"COCO Dataset Metrics:\")\n",
    "    else:\n",
    "        print(\"ImageNet Dataset Metrics:\")\n",
    "\n",
    "    print(f\"Average SSIM: {avg_ssim:.3f} ± {std_ssim:.3f}\")\n",
    "    print(f\"Average Colorfulness: {avg_colorfulness:.3f} ± {std_colorfulness:.3f}\")\n",
    "    print(f\"Average Color Harmony: {avg_color_harmony:.3f} ± {std_color_harmony:.3f}\")\n",
    "    print(f\"Average Color Balance: {avg_color_balance:.3f} ± {std_color_balance:.3f}\")\n",
    "    print(f\"Average PCQI: {avg_pcqi:.3f} ± {std_pcqi:.3f}\")\n",
    "    print(f\"Average LPIPS: {avg_lpips:.3f} ± {std_lpips:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee3e03d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:07<00:00,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO Dataset Metrics:\n",
      "Average SSIM: 0.855 ± 0.067\n",
      "Average Colorfulness: 137.096 ± 36.207\n",
      "Average Color Harmony: 0.004 ± 0.028\n",
      "Average Color Balance: 1.664 ± 0.175\n",
      "Average PCQI: 1.874 ± 0.469\n",
      "Average LPIPS: 0.187 ± 0.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval(paths_coco_test, colorized_results_coco)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da8865dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:17<00:00,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageNet Dataset Metrics:\n",
      "Average SSIM: 0.865 ± 0.064\n",
      "Average Colorfulness: 138.715 ± 31.677\n",
      "Average Color Harmony: 0.002 ± 0.007\n",
      "Average Color Balance: 1.681 ± 0.146\n",
      "Average PCQI: 1.795 ± 0.464\n",
      "Average LPIPS: 0.243 ± 0.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval(paths_image_net_test, colorized_results_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c946ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Directory to save the images\n",
    "output_dir1 = \"ensemble_results_coco\"\n",
    "output_dir2 = \"ensemble_original_coco\"\n",
    "os.makedirs(output_dir1, exist_ok=True)\n",
    "os.makedirs(output_dir2, exist_ok=True)\n",
    "\n",
    "# Save the first 100 images\n",
    "for i, images in enumerate(colorized_results_coco[:100]):\n",
    "    orig_img, colorized_rgb = images\n",
    "    orig_img = Image.open(orig_img).convert(\"RGB\")\n",
    "    orig_img.save(os.path.join(output_dir1, f\"original{i+1}.png\"))\n",
    "    colorized_rgb = colorized_rgb.permute(1, 2, 0).numpy()  # Convert CHW to HWC\n",
    "    colorized_rgb = Image.fromarray(colorized_rgb.astype('uint8'))\n",
    "    colorized_rgb.save(os.path.join(output_dir2, f\"colorised{i+1}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c594c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the images\n",
    "output_dir1 = \"ensemble_results_imagenet\"\n",
    "output_dir2 = \"ensemble_original_imagenet\"\n",
    "os.makedirs(output_dir1, exist_ok=True)\n",
    "os.makedirs(output_dir2, exist_ok=True)\n",
    "\n",
    "# Save the first 100 images\n",
    "for i, images in enumerate(colorized_results_imagenet[:100]):\n",
    "    orig_img, colorized_rgb = images\n",
    "    orig_img = Image.open(orig_img).convert(\"RGB\")\n",
    "    orig_img.save(os.path.join(output_dir1, f\"original{i+1}.png\"))\n",
    "    colorized_rgb = colorized_rgb.permute(1, 2, 0).numpy()  # Convert CHW to HWC\n",
    "    colorized_rgb = Image.fromarray(colorized_rgb.astype('uint8'))\n",
    "    colorized_rgb.save(os.path.join(output_dir2, f\"colorised{i+1}.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
